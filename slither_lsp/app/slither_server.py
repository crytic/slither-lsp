import logging
import os
from concurrent.futures import ThreadPoolExecutor, wait
from functools import lru_cache
from threading import Lock
from time import sleep
from typing import Dict, List, Optional, Set, Type, Callable, Set

import lsprotocol.types as lsp
from crytic_compile.crytic_compile import CryticCompile
from crytic_compile.platform.solc_standard_json import SolcStandardJson
from pygls.lsp import METHOD_TO_OPTIONS
from pygls.protocol import LanguageServerProtocol
from pygls.server import LanguageServer
from slither import Slither
from slither.__main__ import (
    _process as process_detectors_and_printers,
)
from slither.__main__ import (
    get_detectors_and_printers,
)
from slither.core.source_mapping.source_mapping import Source

from slither_lsp.app.feature_analyses.slither_diagnostics import SlitherDiagnostics
from slither_lsp.app.types.analysis_structures import (
    AnalysisResult,
    CompilationTarget,
    CompilationTargetBasic,
    CompilationTargetType,
    SlitherDetectorResult,
    SlitherDetectorSettings,
)
from slither_lsp.app.types.params import (
    ANALYSIS_REPORT_ANALYSIS_PROGRESS,
    COMPILATION_SET_COMPILATION_TARGETS,
    METHOD_TO_TYPES,
    SLITHER_SET_DETECTOR_SETTINGS,
    AnalysisProgressParams,
    AnalysisResultProgress,
    SetCompilationTargetsParams,
)
from slither_lsp.app.utils.file_paths import (
    fs_path_to_uri,
    get_solidity_files,
    is_solidity_file,
    normalize_uri,
    uri_to_fs_path,
)

# TODO(frabert): Maybe this should be upstreamed? https://github.com/openlawlibrary/pygls/discussions/338
METHOD_TO_OPTIONS[lsp.WORKSPACE_DID_CHANGE_WATCHED_FILES] = (
    lsp.DidChangeWatchedFilesRegistrationOptions
)


class SlitherProtocol(LanguageServerProtocol):
    # See https://github.com/openlawlibrary/pygls/discussions/441

    @lru_cache
    def get_message_type(self, method: str) -> Optional[Type]:
        return METHOD_TO_TYPES.get(method, (None,))[0] or super().get_message_type(
            method
        )

    @lru_cache
    def get_result_type(self, method: str) -> Optional[Type]:
        return METHOD_TO_TYPES.get(method, (None, None))[1] or super().get_result_type(
            method
        )


class SlitherServer(LanguageServer):
    _logger: logging.Logger
    _init_params: Optional[lsp.InitializeParams] = None

    # Define our workspace parameters.
    workspace_folders: Dict[str, lsp.WorkspaceFolder] = {}
    open_text_documents: Dict[str, lsp.TextDocumentItem] = {}

    # Define our analysis variables

    # Define a set of all solidity files available in the workspace which we track with appropriate file events.
    solidity_file_uris: Set[str] = set()
    solidity_files_lock = Lock()  # lock for updating the above
    _solidity_files_scan_required = (
        True  # determines if we need to scan filesystem for all solidity files
    )

    # Define a set of compilation targets which are autogenerated if not user supplied.
    compilation_targets: List[CompilationTarget] = []
    compilation_targets_lock = Lock()  # lock for updating the above
    compilation_targets_autogenerate = True
    compilation_targets_enabled = False

    # Define our compilation variables
    analyses: List[AnalysisResult] = []

    # Define our slither diagnostics provider
    detector_settings: SlitherDetectorSettings = SlitherDetectorSettings(
        enabled=True, hidden_checks=[]
    )
    slither_diagnostics: Optional[SlitherDiagnostics] = None

    refresh_lock = (
        Lock()
    )  # Makes sure at most one refresh operation is in flight at any point in time
    REFRESH_WAIT_SECONDS = 1.0

    analysis_pool = ThreadPoolExecutor()

    def __init__(self, logger: logging.Logger, *args):
        super().__init__(protocol_cls=SlitherProtocol, *args)

        self._logger = logger
        self.slither_diagnostics = SlitherDiagnostics(self)

        @self.feature(lsp.INITIALIZE)
        def on_initialize(ls: SlitherServer, params):
            ls._on_initialize(params)

        @self.feature(lsp.INITIALIZED)
        def on_initialized(ls: SlitherServer, params):
            ls.show_message("slither-lsp initialized", lsp.MessageType.Debug)

        @self.thread()
        @self.feature(
            lsp.WORKSPACE_DID_CHANGE_WATCHED_FILES,
            lsp.DidChangeWatchedFilesRegistrationOptions(
                [lsp.FileSystemWatcher("**/*.sol")]
            ),
        )
        def on_did_change_watched_files(ls: SlitherServer, params):
            ls._on_did_change_watched_files(params)

        @self.thread()
        @self.feature(lsp.WORKSPACE_DID_CHANGE_WORKSPACE_FOLDERS)
        def on_did_change_workspace_folder(ls: SlitherServer, params):
            ls._on_did_change_workspace_folders(params)

        @self.thread()
        @self.feature(lsp.TEXT_DOCUMENT_DID_CLOSE)
        def on_did_close_text_document(ls: SlitherServer, params):
            ls._on_did_close_text_document(params)

        @self.thread()
        @self.feature(lsp.TEXT_DOCUMENT_DID_OPEN)
        def on_text_document_did_open(ls: SlitherServer, params):
            ls._on_did_open_text_document(params)

        @self.thread()
        @self.feature(SLITHER_SET_DETECTOR_SETTINGS)
        def on_set_detector_settings(ls: SlitherServer, params):
            ls._on_set_detector_settings(params)

        @self.thread()
        @self.feature(COMPILATION_SET_COMPILATION_TARGETS)
        def on_set_compilation_targets(ls: SlitherServer, params):
            ls._on_set_compilation_targets(params)

        @self.thread()
        @self.feature(lsp.TEXT_DOCUMENT_DEFINITION)
        def on_goto_definition(ls: SlitherServer, params):
            return ls._on_goto_definition(params)

        @self.thread()
        @self.feature(lsp.TEXT_DOCUMENT_IMPLEMENTATION)
        def on_goto_implementation(ls: SlitherServer, params):
            return ls._on_goto_implementation(params)

        @self.thread()
        @self.feature(lsp.TEXT_DOCUMENT_REFERENCES)
        def on_find_references(ls: SlitherServer, params):
            return ls._on_find_references(params)

    @property
    def workspace_opened(self):
        """
        If True, indicates a workspace folder has been opened.
        If False, no workspace folder is opened and files in opened tabs will be targeted.
        :return: None
        """
        return len(self.workspace_folders) > 0

    def _on_initialize(self, params: lsp.InitializeParams) -> None:
        """
        Sets initial data when the server is spun up, such as workspace folders.
        :param params: The client's initialization parameters.
        :param result: The server response to the client's initialization parameters.
        :return: None
        """
        # Set our workspace folder on initialization.
        self._init_params = params
        self.workspace_folders = {
            workspace_folder.uri: workspace_folder
            for workspace_folder in self._init_params.workspace_folders or []
        }
        self.open_text_documents = {}

    def queue_reanalysis(self, files_rescan: bool = False) -> None:
        """
        Queues all compilation targets for reanalysis.
        :param files_rescan: If True, indicates the list of Solidity files in the workspace will be
        re-evaluated.
        :return: None
        """
        # Update the tracked solidity files in the workspace if requested.
        with self.solidity_files_lock:
            if files_rescan:
                self._solidity_files_scan_required = True

        self.refresh_workspace()

    def _on_did_change_workspace_folders(
        self, params: lsp.DidChangeWorkspaceFoldersParams
    ) -> None:
        """
        Applies client-reported changes to the workspace folders.
        :param params: The client's workspace change message parameters.
        :return: None
        """
        # Apply changes to workspace folders.
        with self.solidity_files_lock:
            for added in params.event.added:
                self.workspace_folders[normalize_uri(added.uri)] = added
            for removed in params.event.removed:
                self.workspace_folders.pop(normalize_uri(removed.uri), None)

        # Trigger a re-scan of the workspace Solidity files and re-analyze the codebase.
        self.queue_reanalysis(files_rescan=True)

    def _on_did_open_text_document(self, params: lsp.DidOpenTextDocumentParams) -> None:
        """
        Applies changes to the workspace state as a new file was opened.
        :param params: The client's text document opened message parameters.
        :return: None
        """
        # Update our open text document lookup.
        self.open_text_documents[normalize_uri(params.text_document.uri)] = (
            params.text_document
        )

        # If we have no workspace folders open, update our solidity files list and re-analyze immediately.
        if not self.workspace_opened:
            self.queue_reanalysis(files_rescan=True)

    def _on_did_close_text_document(
        self, params: lsp.DidCloseTextDocumentParams
    ) -> None:
        """
        Applies changes to the workspace state as an opened file was closed.
        :param params: The client's text document closed message parameters.
        :return: None
        """
        # Update our open text document lookup.
        self.open_text_documents.pop(normalize_uri(params.text_document.uri), None)

        # If we have no workspace folders open, update our solidity files list and re-analyze immediately.
        if not self.workspace_opened:
            self.queue_reanalysis(files_rescan=True)

    def _on_did_change_watched_files(
        self, params: lsp.DidChangeWatchedFilesParams
    ) -> None:
        """
        Applies changes to the workspace state as files were changed.
        :param params: The client's watched file change parameters.
        :return: None
        """
        # Update our solidity file list
        updated_solidity_files = False
        with self.solidity_files_lock:
            for file_event in params.changes:
                target_uri = normalize_uri(file_event.uri)
                if (
                    file_event.type == lsp.FileChangeType.Created
                    or file_event.type == lsp.FileChangeType.Changed
                ):
                    self.solidity_file_uris.add(target_uri)
                elif file_event.type == lsp.FileChangeType.Deleted:
                    self.solidity_file_uris.remove(target_uri)
                updated_solidity_files = updated_solidity_files or is_solidity_file(
                    target_uri
                )

        # Set our analysis pending status to signal for reanalysis.
        if updated_solidity_files:
            self.queue_reanalysis()

    def _on_set_detector_settings(self, params: SlitherDetectorSettings) -> None:
        """
        Sets the detector settings for the workspace, indicating how detector output should be presented.
        :param params: The parameters provided for the set detector settings request.
        :return: None
        """
        # If our detector settings are not different than existing ones, we do not need to trigger any on-change events.
        if params == self.detector_settings:
            return

        # Set our detector settings
        self.detector_settings = params

        # Refresh our detector output
        self._refresh_detector_output()

    def _on_set_compilation_targets(self, params: SetCompilationTargetsParams) -> None:
        """
        Sets the compilation targets for the workspace to use. If empty, auto-compilation will be used instead.
        :param params: The parameters provided for the set compilation request.
        :return: None
        """
        # Update our solidity file list
        with self.compilation_targets_lock:
            # Update our list of compilation targets
            self.compilation_targets = params.targets
            self.compilation_targets_enabled = True
            self.compilation_targets_autogenerate = len(self.compilation_targets) == 0

        # Set our analysis pending status to signal for reanalysis.
        self.queue_reanalysis(files_rescan=True)

    def _report_compilation_progress(self) -> None:
        """
        Reports current analysis progress to the client.
        :return: None
        """
        # Create a list of progress reports for each analysis result.
        report_progress_params_results: List[AnalysisResultProgress] = []

        # Report on progress for each compilation target
        for compilation_target in self.compilation_targets:
            # See if we can find a corresponding analysis.
            corresponding_analysis: Optional[AnalysisResult] = None
            for analysis in self.analyses:
                if analysis.compilation_target == compilation_target:
                    corresponding_analysis = analysis

            # Add progress for this compilation target
            report_progress_params_results.append(
                AnalysisResultProgress(
                    succeeded=(
                        None
                        if corresponding_analysis is None
                        else corresponding_analysis.succeeded
                    ),
                    compilation_target=compilation_target,
                    error=(
                        None
                        if corresponding_analysis is None
                        or corresponding_analysis.error is None
                        else str(corresponding_analysis.error)
                    ),
                )
            )

        # Send the reports to the client.
        report_progress_params = AnalysisProgressParams(
            results=report_progress_params_results
        )
        self.send_notification(
            ANALYSIS_REPORT_ANALYSIS_PROGRESS, report_progress_params
        )

    def _refresh_detector_output(self):
        """
        Refreshes language server state given new analyses output or detector settings.
        :return: None
        """
        # Update our diagnostics with new detector output.
        self.slither_diagnostics.update(self.analyses, self.detector_settings)

    def refresh_workspace(self) -> None:
        """
        Refreshes the currently opened workspace state, tracking new files if a workspace change occurred, re-running
        compilation and analysis if needed, and refreshing analysis output such as for slither detectors.
        :return:
        """
        detector_classes, _ = get_detectors_and_printers()

        def analyze(compilation_target: CompilationTarget):
            analyzed_successfully = True
            compilation: Optional[CryticCompile] = None
            analysis = None
            analysis_error = None
            detector_results = None
            try:
                self._logger.info(
                    "Started compiling %s",
                    compilation_target.target_basic.target,
                )
                # Compile our target
                compilation = self._compile_target(compilation_target)

                # Create our analysis.
                analysis = Slither(compilation)

                # Run detectors and obtain results
                self._logger.info(
                    "Processing %s", compilation_target.target_basic.target
                )
                _, detector_results, _, _ = process_detectors_and_printers(
                    analysis, detector_classes, []
                )
                # Parse detector results
                if detector_results is not None and isinstance(detector_results, list):
                    detector_results = [
                        SlitherDetectorResult.from_dict(detector_result)
                        for detector_result in detector_results
                    ]
                else:
                    detector_results = None

            except Exception as err:
                self._logger.error(
                    "Failed compiling %s: %s",
                    compilation_target.target_basic.target,
                    err,
                )
                # If we encounter an error, set our status.
                analyzed_successfully = False
                analysis_error = err

            self._logger.info(
                "Done compiling %s", compilation_target.target_basic.target
            )

            # Add our analysis
            self.analyses.append(
                AnalysisResult(
                    succeeded=analyzed_successfully,
                    compilation_target=compilation_target,
                    compilation=compilation,
                    analysis=analysis,
                    error=analysis_error,
                    detector_results=detector_results,
                )
            )

            # Report analysis status to our client
            self._report_compilation_progress()

        def start_refresh():
            # Gives a chance to the main thread to update the compilation targets before starting
            sleep(self.REFRESH_WAIT_SECONDS)

            with self.refresh_lock:
                targets_copy = []
                with self.compilation_targets_lock:
                    targets_copy = self.compilation_targets.copy()

                futures = [
                    self.analysis_pool.submit(analyze, target)
                    for target in targets_copy
                ]
                wait(futures)

                # Refresh our detector results
                self._refresh_detector_output()

        # First refresh our initial solidity target list for this workspace
        with self.solidity_files_lock:
            # If we're meant to re-scan our solidity files, do so to get an initial collection of solidity target
            # locations. This can happen on initialization or workspace folder change.
            if self._solidity_files_scan_required:
                # If we have no workspace folders, we'll instead use our open text documents as targets.
                if not self.workspace_opened:
                    self.solidity_file_uris = set(
                        [
                            open_doc.uri
                            for open_doc in self.open_text_documents.values()
                            if is_solidity_file(open_doc.uri)
                        ]
                    )
                else:
                    solidity_file_paths = get_solidity_files(
                        [
                            uri_to_fs_path(workspace_folder.uri)
                            for workspace_folder in self.workspace_folders.values()
                        ]
                    )
                    self.solidity_file_uris = set(
                        [fs_path_to_uri(fspath) for fspath in solidity_file_paths]
                    )
                self._solidity_files_scan_required = False

            # Regenerate new compilation targets if desired.
            with self.compilation_targets_lock:
                if self.compilation_targets_autogenerate:
                    self.compilation_targets = self.generate_compilation_targets()

        self.analysis_pool.submit(start_refresh)

    def generate_compilation_targets(self) -> List[CompilationTarget]:
        # TODO: Loop through self.solidity_files, parse files to determine which compilation buckets/parameters
        #  should be used.

        # TODO: Parse import strings, create remappings for unresolved imports.
        # Regex: import\s+[^"]*"([^"]+)".*;

        # TODO: Parse semvers, find incompatibilities, put them into different compilation buckets
        #  and potentially return data about satisfactory solc versions, which may enable us to
        #  use solc-select to compile all.
        # Regex: pragma\s+solidity\s+(.*);

        file_paths = map(uri_to_fs_path, self.solidity_file_uris)
        workspaces = map(uri_to_fs_path, self.workspace_folders)
        targets = map(
            lambda path: CompilationTarget(
                target_type=CompilationTargetType.BASIC,
                target_basic=CompilationTargetBasic(path),
                cwd_workspace=next(
                    filter(
                        lambda folder: os.path.commonprefix([path, folder]) == folder,
                        workspaces,
                    ),
                    None,
                ),
                crytic_compile_args=None,
            ),
            file_paths,
        )

        return list(targets)

    def _compile_target(self, compilation_settings: CompilationTarget) -> CryticCompile:
        """
        Compiles a target with the provided compilation settings using crytic-compile.
        :return: Returns an instance of crytic-compile.
        """
        if compilation_settings.target_type == CompilationTargetType.BASIC:
            # If the target type is a basic target and we have provided settings, pass them to crytic compile.
            if compilation_settings.target_basic is not None:
                # Obtain our workspace folder
                workspace_folder_path: Optional[str] = None
                if compilation_settings.cwd_workspace is not None:
                    for workspace_folder in self.workspace_folders.values():
                        if (
                            workspace_folder.name.lower()
                            == compilation_settings.cwd_workspace.lower()
                        ):
                            workspace_folder_path = uri_to_fs_path(workspace_folder.uri)
                            break

                # Obtain our target. If this is a relative path, we prepend our working directory.
                target_path = compilation_settings.target_basic.target
                if not os.path.isabs(target_path) and workspace_folder_path is not None:
                    target_path = os.path.normpath(
                        os.path.join(workspace_folder_path, target_path)
                    )

                # Compile our target
                return CryticCompile(
                    target_path, cwd=compilation_settings.cwd_workspace
                )

        elif compilation_settings.target_type == CompilationTargetType.STANDARD_JSON:
            # If the target type is standard json and we have provided settings, pass them to crytic compile.
            if compilation_settings.target_standard_json is not None:
                # TODO: Add support for other arguments (solc_working_dir, etc)
                return CryticCompile(
                    SolcStandardJson(compilation_settings.target_standard_json.target)
                )

        # Raise an exception if there was no relevant exception.
        raise ValueError(
            f"Could not compile target type {compilation_settings.target_type.name} as insufficient settings were "
            f"provided."
        )

    @staticmethod
    def _source_to_location(source: Source) -> Optional[lsp.Location]:
        """
        Converts a slither Source mapping object into a Language Server Protocol Location.
        :param source: The slither Source mapping object to convert into a Location.
        :return: Returns a Location representing the slither Source mapping object. None if no valid mapping exists.
        """
        # If there are no mapped lines, we don't return a location.
        if len(source.lines) == 0:
            return None

        # Otherwise we can return a location fairly easily.
        return lsp.Location(
            uri=fs_path_to_uri(source.filename.absolute),
            range=lsp.Range(
                start=lsp.Position(
                    line=source.lines[0] - 1,
                    character=max(0, source.starting_column - 1),
                ),
                end=lsp.Position(
                    line=source.lines[-1] - 1,
                    character=max(0, source.ending_column - 1),
                ),
            ),
        )

    def _inspect_analyses(
        self,
        target_filename_str: str,
        line: int,
        col: int,
        func: Callable[[Slither, int], Set[Source]],
    ) -> List[lsp.Location]:
        # Compile a list of definitions
        results = []

        # According to https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe
        # there's no need to acquire a lock here
        analyses_copy = self.analyses.copy()

        # Loop through all compilations
        for analysis_result in analyses_copy:
            if analysis_result.analysis is not None:
                # TODO: Remove this temporary try/catch once we refactor crytic-compile to now throw errors in
                #  these functions.
                try:
                    # Obtain the offset for this line + character position
                    target_offset = (
                        analysis_result.compilation.get_global_offset_from_line(
                            target_filename_str, line
                        )
                    )
                    # Obtain sources
                    sources = func(analysis_result.analysis, target_offset + col)
                except Exception:
                    continue
                else:
                    # Add all definitions from this source.
                    for source in sources:
                        source_location: Optional[lsp.Location] = (
                            self._source_to_location(source)
                        )
                        if source_location is not None:
                            results.append(source_location)

        return results

    def _on_goto_definition(self, params: lsp.DefinitionParams) -> List[lsp.Location]:
        # Obtain our filename for this file
        target_filename_str: str = uri_to_fs_path(params.text_document.uri)

        return self._inspect_analyses(
            target_filename_str,
            params.position.line + 1,
            params.position.character,
            lambda analysis, offset: analysis.offset_to_definitions(
                target_filename_str, offset
            ),
        )

    def _on_goto_implementation(
        self, params: lsp.ImplementationParams
    ) -> List[lsp.Location]:
        # Obtain our filename for this file
        target_filename_str: str = uri_to_fs_path(params.text_document.uri)

        return self._inspect_analyses(
            target_filename_str,
            params.position.line + 1,
            params.position.character,
            lambda analysis, offset: analysis.offset_to_implementations(
                target_filename_str, offset
            ),
        )

    def _on_find_references(
        self, params: lsp.ImplementationParams
    ) -> Optional[List[lsp.Location]]:
        # Obtain our filename for this file
        target_filename_str: str = uri_to_fs_path(params.text_document.uri)

        return self._inspect_analyses(
            target_filename_str,
            params.position.line + 1,
            params.position.character,
            lambda analysis, offset: analysis.offset_to_references(
                target_filename_str, offset
            ),
        )

import os
import time
import uuid
from dataclasses import dataclass
from threading import Lock
from time import sleep
from typing import Iterable, Set, List, Dict, Optional, Any
from urllib.parse import urlparse, unquote_plus, urljoin
from urllib.request import url2pathname, pathname2url

from crytic_compile import CryticCompile
from crytic_compile.platform.solc_standard_json import SolcStandardJson
from slither import Slither
from slither_lsp.app.requests.analysis.report_analysis_progress import ReportAnalysisProgressNotification

from slither_lsp.app.types.params import SetCompilationTargetsParams, AnalysisProgressParams, AnalysisResultProgress
from slither_lsp.app.types.analysis_structures import CompilationTarget, CompilationTargetStandardJson, \
    CompilationTargetType, AnalysisResult
from slither_lsp.app.utils.file_paths import is_solidity_file, get_solidity_files, fs_path_to_uri, uri_to_fs_path
from slither_lsp.lsp.request_handlers.workspace.did_change_watched_files import DidChangeWatchedFilesHandler
from slither_lsp.lsp.requests.client.register_capability import RegisterCapabilityRequest
from slither_lsp.lsp.types.basic_structures import WorkspaceFolder, TextDocumentItem
from slither_lsp.lsp.types.params import InitializeResult, InitializeParams, DidChangeWorkspaceFoldersParams, \
    DidOpenTextDocumentParams, DidCloseTextDocumentParams, RegistrationParams, DidChangeWatchedFilesParams, \
    DidChangeTextDocumentParams, \
    FileChangeType
from slither_lsp.lsp.types.registration_options import DidChangeWatchedFilesRegistrationOptions, FileSystemWatcher


@dataclass
class SolidityFile:
    """
    Describes a Solidity file, it's dependencies, and any version pragma it has.
    """
    path: str

    dependencies: List[str]

    version_spec: Any


class SolidityWorkspace:
    """
    Provides a set of methods for tracking and managing Solidity files in a workspace.
    """
    _FILE_CHANGE_POLLING_INTERVAL_SECONDS = 0.2
    _FILE_CHANGE_ANALYSIS_DELAY_SECONDS = 2.0

    def __init__(self, app):
        # Late import to avoid circular reference issues
        from slither_lsp.app.app import SlitherLSPApp

        # Set our main parameters.
        self.app: SlitherLSPApp = app
        self._init_params: Optional[InitializeParams] = None
        self._shutdown: bool = False

        # Define our workspace parameters.
        self._watch_files_registration_id = str(uuid.uuid4())  # obtain a random uuid for our registration id.
        self.workspace_folders: Dict[str, WorkspaceFolder] = {}
        self.open_text_documents: Dict[str, TextDocumentItem] = {}

        # Define our analysis variables

        # Define a set of all solidity files available in the workspace which we track with appropriate file events.
        self.solidity_file_uris: Set[str] = set()
        self.solidity_files_lock = Lock()  # lock for updating the above
        self._solidity_files_scan_required = True  # determines if we need to scan filesystem for all solidity files

        # Define a variable to indicate when a change was made to the workspace that requires reanalysis.
        # If None, no changes were made and reanalysis is not necessary.
        self._analysis_last_change_time: Optional[float] = 0

        # Define a set of compilation targets which are autogenerated if not user supplied.
        self.compilation_targets: List[CompilationTarget] = []
        self.compilation_targets_lock = Lock()  # lock for updating the above
        self.compilation_targets_autogenerate = True
        self.compilation_targets_enabled = False

        # Define our compilation variables
        self.analyses: List[AnalysisResult] = []
        self.analyses_lock = Lock()

        # Register our event handlers. Some are registered synchronously so as not to waste resources spinning up
        # a thread. This is fine so long as we do not hang up the thread for long. Any potentially longer running
        # event handlers should be run asynchronously.
        self.app.server.event_emitter.on(
            'server.initialized',
            self._on_server_initialized,
            asynchronous=False
        )
        self.app.server.event_emitter.on(
            'client.initialized',
            self.main_loop,
            asynchronous=True
        )
        self.app.server.event_emitter.on(
            'workspace.didChangeWorkspaceFolders',
            self._on_did_change_workspace_folders,
            asynchronous=False
        )
        self.app.server.event_emitter.on(
            'workspace.didChangeWatchedFiles',
            self._on_did_change_watched_files,
            asynchronous=False
        )
        self.app.server.event_emitter.on(
            'textDocument.didOpen',
            self._on_did_open_text_document,
            asynchronous=False
        )
        self.app.server.event_emitter.on(
            'textDocument.didClose',
            self._on_did_close_text_document,
            asynchronous=False
        )
        self.app.server.event_emitter.on(
            'textDocument.didChange',
            self._on_did_close_text_document,
            asynchronous=False
        )

        # Add event handlers for application layer specific commands.
        self.app.server.event_emitter.on(
            'compilation.setCompilationTargets',
            self._on_set_compilation_targets,
            asynchronous=True
        )

    @property
    def workspace_opened(self):
        """
        If True, indicates a workspace folder has been opened.
        If False, no workspace folder is opened and files in opened tabs will be targeted.
        :return: None
        """
        return len(self.workspace_folders) > 0

    def main_loop(self) -> None:
        """
        Runs the main loop, updating state of the Solidity workspace continuously.. This stops executing when
        shutdown() is called, or when the language server receives a shutdown request.
        :return: None
        """
        # Register for our file watching operations on Solidity files.
        RegisterCapabilityRequest.send(
            context=self.app.server.context,
            params=RegistrationParams(
                registrations=[
                    DidChangeWatchedFilesHandler.get_registration(
                        context=self.app.server.context,
                        registration_id=self._watch_files_registration_id,
                        registration_options=DidChangeWatchedFilesRegistrationOptions([
                            FileSystemWatcher(glob_pattern='**/*.sol', kind=None)
                        ])
                    )
                ]
            )
        )

        # Queue for analysis on startup
        self._queue_reanalysis(files_rescan=True, force_analysis=True)

        # Loop while a shutdown was not signalled, we want to keep performing reanalysis if there are valid changes
        # requiring it. Similarly, we want to be sure compilation targets are enabled.
        while not self._shutdown and not self.app.server.context.shutdown:
            # Perform new analysis and change our status.
            self.refresh_workspace()

            # Sleep for our polling interval before trying again.
            sleep(self._FILE_CHANGE_POLLING_INTERVAL_SECONDS)

    def shutdown(self):
        """
        Signals that this workspace object should shutdown.
        :return:
        """
        self._shutdown = True

    def _queue_reanalysis(self, files_rescan: bool = False, force_analysis: bool = False) -> None:
        """
        Queues all compilation targets for reanalysis.
        :param files_rescan: If True, indicates the list of Solidity files in the workspace will be
        re-evaluated.
        :param force_analysis: If True, indicates the last analysis time will be set to zero so a reanalysis
        will be triggered in the next polling interval. Otherwise it will be recompiled at the first polling round after
        the delay time has elapsed.
        :return: None
        """
        # Update the tracked solidity files in the workspace if requested.
        with self.solidity_files_lock:
            if files_rescan:
                self._solidity_files_scan_required = True

        # Set our analysis time.
        with self.analyses_lock:
            self._analysis_last_change_time = 0 if force_analysis else time.time()

    def _on_server_initialized(self, params: InitializeParams, result: InitializeResult) -> None:
        """
        Sets initial data when the server is spun up, such as workspace folders.
        :param params: The client's initialization parameters.
        :param result: The server response to the client's initialization parameters.
        :return: None
        """
        # Set our workspace folder on initialization.
        self._init_params = params
        self.workspace_folders = {
            workspace_folder.uri: workspace_folder
            for workspace_folder in self._init_params.workspace_folders or []
        }
        self.open_text_documents = {}

    def _on_did_change_workspace_folders(self, params: DidChangeWorkspaceFoldersParams) -> None:
        """
        Applies client-reported changes to the workspace folders.
        :param params: The client's workspace change message parameters.
        :return: None
        """
        # Apply changes to workspace folders.
        with self.solidity_files_lock:
            for added in params.event.added:
                self.workspace_folders[added.uri] = added
            for removed in params.event.removed:
                self.workspace_folders.pop(removed.uri, None)

            # Trigger a re-scan of the workspace Solidity files and re-analyze the codebase.
            self._queue_reanalysis(files_rescan=True, force_analysis=True)

    def _on_did_open_text_document(self, params: DidOpenTextDocumentParams) -> None:
        """
        Applies changes to the workspace state as a new file was opened.
        :param params: The client's text document opened message parameters.
        :return: None
        """
        # Update our open text document lookup.
        self.open_text_documents[params.text_document.uri] = params.text_document

        # If we have no workspace folders open, update our solidity files list and re-analyze immediately.
        if not self.workspace_opened:
            self._queue_reanalysis(files_rescan=True, force_analysis=True)

    def _on_did_close_text_document(self, params: DidCloseTextDocumentParams) -> None:
        """
        Applies changes to the workspace state as an opened file was closed.
        :param params: The client's text document closed message parameters.
        :return: None
        """
        # Update our open text document lookup.
        self.open_text_documents.pop(params.text_document.uri, None)

        # If we have no workspace folders open, update our solidity files list and re-analyze immediately.
        if not self.workspace_opened:
            self._queue_reanalysis(files_rescan=True, force_analysis=True)

    def _on_did_change_text_document(self, params: DidChangeTextDocumentParams) -> None:
        """
        Applies changes to the workspace state as an opened file was changed.
        :param params: The client's text document closed message parameters.
        :return: None
        """
        # TODO: This should invalidate some analysis in this file until it is saved and re-analysis occurs
        #  via on_did_change_watched_files.
        pass

    def _on_did_change_watched_files(self, params: DidChangeWatchedFilesParams) -> None:
        """
        Applies changes to the workspace state as files were changed.
        :param params: The client's watched file change parameters.
        :return: None
        """
        # Update our solidity file list
        updated_solidity_files = False
        with self.solidity_files_lock:
            for file_event in params.changes:
                if file_event.type == FileChangeType.CREATED or file_event.type == FileChangeType.CHANGED:
                    self.solidity_file_uris.add(file_event.uri)
                elif file_event.type == FileChangeType.DELETED:
                    self.solidity_file_uris.remove(file_event.uri)
                updated_solidity_files = updated_solidity_files or is_solidity_file(file_event.uri)

        # Set our analysis pending status to signal for reanalysis.
        if updated_solidity_files:
            self._queue_reanalysis()

    def _on_set_compilation_targets(self, params: SetCompilationTargetsParams) -> None:
        """
        Sets the compilation targets for the workspace to use. If empty, auto-compilation will be used instead.
        :param params: The parameters provided for the set compilation request.
        :return: None
        """
        self.set_compilation_targets(params.targets)

    def set_compilation_targets(self, targets: List[CompilationTarget]) -> None:
        """
        Sets the compilation targets to be autogenerated and sets them into a pending generation state.
        :return: None
        """
        # Update our solidity file list
        with self.compilation_targets_lock:
            # Update our list of compilation targets
            self.compilation_targets = targets
            self.compilation_targets_enabled = True
            self.compilation_targets_autogenerate = len(self.compilation_targets) == 0

        # Set our analysis pending status to signal for reanalysis.
        self._queue_reanalysis(files_rescan=True, force_analysis=True)

    def _report_compilation_progress(self) -> None:
        """
        Reports current analysis progress to the client.
        :return: None
        """
        # Create a list of progress reports for each analysis result.
        report_progress_params_results: List[AnalysisResultProgress] = []

        # Report on progress for each compilation target
        for compilation_target in self.compilation_targets:
            # See if we can find a corresponding analysis.
            corresponding_analysis: Optional[AnalysisResult] = None
            for analysis in self.analyses:
                if analysis.compilation_target == compilation_target:
                    corresponding_analysis = analysis

            # Add progress for this compilation target
            report_progress_params_results.append(
                AnalysisResultProgress(
                    succeeded=None if corresponding_analysis is None else corresponding_analysis.succeeded,
                    compilation_target=compilation_target,
                    error=None if corresponding_analysis is None or corresponding_analysis.error is None
                    else str(corresponding_analysis.error)
                )
            )

        # Send the reports to the client.
        report_progress_params = AnalysisProgressParams(results=report_progress_params_results)
        ReportAnalysisProgressNotification.send(
            context=self.app.server.context,
            params=report_progress_params
        )

    def refresh_workspace(self) -> None:
        # First refresh our initial solidity target list for this workspace
        with self.solidity_files_lock:
            # If we're meant to re-scan our solidity files, do so to get an initial collection of solidity target
            # locations. This can happen on initialization or workspace folder change.
            if self._solidity_files_scan_required:
                # If we have no workspace folders, we'll instead use our open text documents as targets.
                if not self.workspace_opened:
                    self.solidity_file_uris = set([
                        open_doc.uri
                        for open_doc in self.open_text_documents.values()
                        if is_solidity_file(open_doc.uri)
                    ])
                else:
                    solidity_file_paths = get_solidity_files([
                        uri_to_fs_path(workspace_folder.uri)
                        for workspace_folder in self.workspace_folders.values()
                    ])
                    self.solidity_file_uris = set([fs_path_to_uri(fspath) for fspath in solidity_file_paths])
                self._solidity_files_scan_required = False

            # Regenerate new compilation targets if desired.
            with self.compilation_targets_lock:
                if self.compilation_targets_autogenerate:
                    self.compilation_targets = self.generate_compilation_targets()

        # Acquire locks for compilation + analysis, and see if our last change time exceeds our delay or we are forcing
        # recompilation.
        with self.compilation_targets_lock:
            with self.analyses_lock:
                if self._analysis_last_change_time is not None and self.compilation_targets_enabled:
                    if time.time() - self._analysis_last_change_time > self._FILE_CHANGE_ANALYSIS_DELAY_SECONDS:
                        self.analyses = []
                        self._report_compilation_progress()
                        for compilation_target in self.compilation_targets:
                            compilation: Optional[CryticCompile] = None
                            analysis = None
                            try:
                                # Compile our target
                                compilation = self._compile_target(compilation_target)

                                # Create our analysis.
                                analysis = Slither(compilation)

                                # Append our result
                                self.analyses.append(
                                    AnalysisResult(
                                        succeeded=True,
                                        compilation_target=compilation_target,
                                        compilation=compilation,
                                        analysis=analysis,
                                        error=None
                                    )
                                )

                            except Exception as err:
                                # TODO: Add error logging message here.
                                self.analyses.append(
                                    AnalysisResult(
                                        succeeded=False,
                                        compilation_target=compilation_target,
                                        compilation=compilation,
                                        analysis=analysis,
                                        error=err
                                    )
                                )

                            self._report_compilation_progress()

                        self._analysis_last_change_time = None

    def generate_compilation_targets(self) -> List[CompilationTarget]:
        # TODO: Loop through self.solidity_files, parse files to determine which compilation buckets/parameters
        #  should be used.

        # TODO: Parse import strings, create remappings for unresolved imports.
        # Regex: import\s+[^"]*"([^"]+)".*;

        # TODO: Parse semvers, find incompatibilities, put them into different compilation buckets
        #  and potentially return data about satisfactory solc versions, which may enable us to
        #  use solc-select to compile all.
        # Regex: pragma\s+solidity\s+(.*);

        # TODO: When we've determined our compilation buckets, create multiple standard json files and return them all.
        if len(self.solidity_file_uris) == 0:
            return []

        # Create our sources section of solc standard json
        sources = {}
        for solidity_file_uri in self.solidity_file_uris:
            solidity_file_path = uri_to_fs_path(solidity_file_uri)
            sources[solidity_file_path] = {
                'urls': [
                    solidity_file_path
                ]
            }

        # Create our standard json result
        target = {
            'language': 'Solidity',
            'sources': sources,
            'settings': {
                'remappings': [],
                'optimizer': {
                    'enabled': False,
                },
                'outputSelection': {
                    '*': {
                        '*': [
                            'abi',
                            'metadata',
                            'devdoc',
                            'userdoc',
                            'evm.bytecode',
                            'evm.deployedBytecode'
                        ],
                        '': [
                            'ast'
                        ]
                    }
                }
            }
        }

        return [CompilationTarget(
            target_type=CompilationTargetType.STANDARD_JSON,
            target_basic=None,
            target_standard_json=CompilationTargetStandardJson(target),
            cwd_workspace=None,
            crytic_compile_args=None)
        ]

    def _compile_target(self, compilation_settings: CompilationTarget) -> CryticCompile:
        """
        Compiles a target with the provided compilation settings using crytic-compile.
        :return: Returns an instance of crytic-compile.
        """
        if compilation_settings.target_type == CompilationTargetType.BASIC:
            # If the target type is a basic target and we have provided settings, pass them to crytic compile.
            if compilation_settings.target_basic is not None:
                # Obtain our workspace folder
                workspace_folder_path: Optional[str] = None
                if compilation_settings.cwd_workspace is not None:
                    for workspace_folder in self.workspace_folders.values():
                        if workspace_folder.name.lower() == compilation_settings.cwd_workspace.lower():
                            workspace_folder_path = uri_to_fs_path(workspace_folder.uri)
                            break

                # Obtain our target. If this is a relative path, we prepend our working directory.
                target_path = compilation_settings.target_basic.target
                if not os.path.isabs(target_path) and workspace_folder_path is not None:
                    target_path = os.path.normpath(os.path.join(workspace_folder_path, target_path))

                # Compile our target
                return CryticCompile(target_path)

        elif compilation_settings.target_type == CompilationTargetType.STANDARD_JSON:
            # If the target type is standard json and we have provided settings, pass them to crytic compile.
            if compilation_settings.target_standard_json is not None:
                # TODO: Add support for other arguments (solc_working_dir, etc)
                return CryticCompile(SolcStandardJson(compilation_settings.target_standard_json.target))

        # Raise an exception if there was no relevant exception.
        raise ValueError(
            f"Could not compile target type {compilation_settings.target_type.name} as insufficient settings were "
            f"provided."
        )
